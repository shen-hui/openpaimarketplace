protocolVersion: 2
name: cifar10-single-mul-DDP-nccl-1
type: job
jobRetryCount: 0
  description: |
    # Pytorch Cifar10 Example

    This example shows how to train a custom neural network on cifar10 with Pytorch on OpenPAI.

    We installed Apex before running `python <script.py>`,and the sample program will be trained on two machines, each with two gpus.

    This example can be run on single-node or on multi-node, using nccl backend for distributed GPU training,nccl currently provides the best distributed GPU training performance, especially for multiprocess single-node or multi-node distributed training.



prerequisites:
  - type: dockerimage
    uri: 'openpai/standard:python_3.6-pytorch_1.2.0-gpu'
    name: docker_image_0
taskRoles:
  worker:
    instances: 2
    completion:
      minFailedInstances: 1
    taskRetryCount: 0
    dockerImage: docker_image_0
    resourcePerInstance:
      gpu: 2
      cpu: 8
      memoryMB: 16384
      ports:
        SynPort: 1
    commands:
      - 'git clone https://github.com/NVIDIA/apex'
      - cd apex
      - python setup.py install
      - cd ..
      - >-
        wget
        https://raw.githubusercontent.com/microsoft/pai/master/examples/Distributed-example/cifar10-single-mul-DDP-nccl-gloo.py
      - >-
        python  cifar10-single-mul-DDP-nccl-gloo.py -n 2 -g 2 --epochs 2
        --dist-backend nccl
defaults:
  virtualCluster: default
extras:
  com.microsoft.pai.runtimeplugin:
    - plugin: ssh
      parameters:
        jobssh: true
        userssh: {}
  hivedScheduler:
    taskRoles:
      worker:
        skuNum: 1
        skuType: null
