protocolVersion: 2
name: grammar_training
type: job
contributor: OpenPAI
description: |
  Grammar Check Model Training Job

  This is a grammar check model training process.
  You could use the prepared data (which stored in $DATA_DIR) as training data, or any dataset follows fairseq model requirements.

prerequisites:
  - name: default_image
    type: dockerimage
    uri: "openpai/standard:python_3.6-pytorch_1.2.0-gpu"
  - name: grammar_data
    type: data
    uri:
      - https://openpaimarketplace.blob.core.windows.net/marketplace/GrammarCheck/gramarCheck_data.tgz
  - name: output
    type: output
    uri: /mnt/confignfs/grammarCheck/output

taskRoles:
  taskrole:
    instances: 1
    dockerImage: default_image
    data: grammar_data
    output: output
    resourcePerInstance:
      cpu: 4
      memoryMB: 8192
      gpu: 1
    commands:
      - mkdir -p /data/grammarCheck/
      - cd /data/grammarCheck/
      - wget <% $data.uri[0] %>
      - tar xvf gramarCheck_data.tgz
      - export DATA_DIR=/data/grammarCheck/dataset
      - mkdir -p /data/grammarCheck/output
      - export OUTPUT_DIR=/data/grammarCheck/
      - export PREPROCESSED_DATA_DIR=./preprocessed_data
      - pip install fairseq==0.9
      - fairseq-preprocess \
      - '--source-lang origin \'
      - '--target-lang correct \'
      - '--trainpref ${DATA_DIR}/processed_data/train \'
      - '--validpref ${DATA_DIR}/processed_data/dev \'
      - '--testpref ${DATA_DIR}/processed_data/test \'
      - "--destdir ${PREPROCESSED_DATA_DIR}"
      - 'fairseq-train ${PREPROCESSED_DATA_DIR} \'
      - '--log-interval 100 \'
      - '--lr 0.25 \'
      - '--clip-norm 0.1 \'
      - '--dropout 0.2  \'
      - '--criterion label_smoothed_cross_entropy \'
      - '--save-dir ${OUTPUT_DIR} \'
      - '-a lstm \'
      - '--max-tokens 4000 \'
      - '--max-epoch 100 \'
      - "--batch-size 256"
